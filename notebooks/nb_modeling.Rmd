---
title: "Frito Lay: Customer Attrition - Multivariate Analysis"
output: 
  github_document:
    html_preview: false
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,       
  warning = FALSE,   
  message = FALSE    
)
```

```{r}
library(tidyverse)
library(caret)
library(e1071)
library(class)
library(naivebayes)
library(scales)
library(ggthemes)
theme_set(theme_economist())
title_format <- function(x) labs(title = x, x = NULL, y = NULL)
```


--------------------------------------------------------------------------------------------------------------------------------------------------


### ------------ Data Loading -------------

```{r}
data <- read.csv("../data/CaseStudy1-data.csv")
```


--------------------------------------------------------------------------------------------------------------------------------------------------


### ------------- Remove Low Variance and Constant Features -------------

```{r}
# Check if each column contains only unique values
unique_check <- sapply(data, function(x) length(unique(x)) == nrow(data))

# Check if each column contains only one unique value
constant_check <- sapply(data, function(x) length(unique(x)) == 1)

col_check <- list(
  constant = names(data)[constant_check],
  unique = names(data)[unique_check]
)

col_check
dim(data)

data_v2 <- data %>%
  select(-one_of(col_check$constant)) %>%
  select(-one_of(col_check$unique))

dim(data_v2)
```


--------------------------------------------------------------------------------------------------------------------------------------------------


### ------------- Convert Categorical Variables to Factors -------------

```{r}
data_v3 <- data_v2 %>%
  mutate_if(is.character, as.factor)
str(data_v3)
```


--------------------------------------------------------------------------------------------------------------------------------------------------


##### ------------- Naive Bayes with 10-fold Cross-Validation -------------

```{r}
set.seed(123)
ctrl <- trainControl(
  method = "cv",
  number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE
)

data_v3$Attrition <- relevel(data_v3$Attrition, ref = "Yes")

nb_cv <- train(
  Attrition ~ .,
  data = data_v3,
  method = "naive_bayes",
  trControl = ctrl,
  metric = "ROC",
  tuneGrid = data.frame(
    laplace   = 0,
    usekernel = FALSE,
    adjust    = 1
  )
)
nb_cv
```


--------------------------------------------------------------------------------------------------------------------------------------------------


### ------------ NB Feature Importance -------------

```{r}
# Extract feature importance from the Naive Bayes model
importance_nb <- varImp(nb_cv)

# View top 10 most important features
print(importance_nb)
plot(importance_nb, top = 10, main = "Top 10 Feature Importances - Naive Bayes")
```

